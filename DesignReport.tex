%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University/School Laboratory Report
% LaTeX Template
% Version 3.0 (4/2/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Linux and Unix Users Group at Virginia Tech Wiki 
% (https://vtluug.org/wiki/Example_LaTeX_chem_lab_report)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{mhchem} % Package for chemical equation typesetting
\usepackage{siunitx} % Provides the \SI{}{} command for typesetting SI units
\usepackage{fullpage} % widens margins in the document

\usepackage{graphicx} % Required for the inclusion of images

\usepackage{listings}
\lstloadlanguages{C}
\lstset{language=C, % Use Perl in this example
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % Perl functions bold and blue
        keywordstyle=[2]\color{Purple}, % Perl function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers                                         
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=5, % 5 spaces per tab
        %
        % Put standard Perl functions not included in the default language here
        morekeywords={rand},
        %
        % Put Perl function parameters here
        morekeywords=[2]{on, off, interp},
        %
        % Put user defined functions here
        morekeywords=[3]{test},
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=5 % Line numbers go in steps of 5
}

\usepackage[left=1in, right=1in]{geometry}

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{Li Tseng - 304272081}
\rhead{Spencer Tung - 004355860}

\headheight = 10pt
\headsep = 15pt

\setlength\parindent{0pt} % Removes all indentation from paragraphs

\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)

%\usepackage{times} % Uncomment to use the Times New Roman font

%----------------------------------------------------------------------------------------
%	DOCUMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Defending Against Process Overload Attacks \\ CS 111} % Title

\author{Linda \textsc{Tseng}
		\and
		Spencer \textsc{Tung}} % Author name

\date{\today} % Date for the report

\begin{document}

\maketitle % Insert the title, author and date

\begin{center}
\begin{tabular}{l r} 
Partners: & Li Tseng 304272081 \\ % Partner names
& Spencer Tung 004355860 \\
Instructor: & Professor Reiher % Instructor/supervisor
\end{tabular}
\end{center}

% If you wish to include an abstract, uncomment the lines below
% \begin{abstract}
% Abstract text
% \end{abstract}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Security Objective}

Our goal is to prevent a process overload attack when using our shell. A 
process overload attack occurs when a process forks more processes than the
underlying operating system can handle. If the operating system is not prepared
to handle this kind of attack, it may cause the kernel to crash. This can 
occur either maliciously or unintentionally\footnote{This actually occurred
during our implementation of lab1c, in which we accidentally created an 
infinite loop while forking our parallel processes. It took another half hour
to regain control long enough to kill all of the rogue processes}, but in 
either case, we must be prepared to mitigate or kill the processes before it 
gets out of control. \\ 

Our implementation will seek to control the flow of the attack and ultimately
kill the processes before they cause our kernel to crash. \\

In summary:
\begin{description}
\item[Primary Objective] \hfill \\
To kill rogue processes from forking uncontrollably.
\item[Secondary Objective] \hfill \\
To ensure fairness in other running processes by reducing the priority of these
rogue processes.
\end{description}

% \subsection{Definitions}
% \label{definitions}
% \begin{description}
% \item[Stoichiometry]
% The relationship between the relative quantities of substances taking part in a reaction or forming a compound, typically a ratio of whole integers.
% \item[Atomic mass]
% The mass of an atom of a chemical element expressed in atomic mass units. It is approximately equivalent to the number of protons and neutrons in the atom (the mass number) or to the average number allowing for the relative abundances of different isotopes. 
% \end{description} 
 
%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Design Overview}

To start, we define a maximum number of processes that our shell (which is 
itself a process) can fork at any given time. This will be our \textbf{hard  
limit}; upon reaching this limit, we will kill the shell and any processes that
were forked from it to begin with. By checking the group process ID (GPID) of 
our shell function, we will be able to count how many other processes have the 
same GPID. We can also verify this through \textbf{pstree}, which creates a
tree of processes that we can refer to when forking. \\
We will also attempt to ensure fairness towards other running processes in the
system by lowering the priority of our shell if it starts to generate a large
number of forked processes. This will be our \textbf{soft limit}, as we will
attempt to slow the forking process first when we reach this limit, rather 
than kill it outright. We assume that when a process hits this limit, it is
possible that it is not a malicious program, and that it just needs more forked
processes than the norm. Therefore, we slow down the forking process to allow 
more time for its previously forked processes to catch up and finish. In the
event that it is indeed a malicious program (or a process that unintentionally 
created an infinite forking loop), then we should take appropriate action when 
we reach the hard limit and kill the process. \\

% \begin{tabular}{ll}
% Mass of empty crucible & \SI{7.28}{g}\\
% Mass of crucible and magnesium before heating & \SI{8.59}{g}\\
% Mass of crucible and magnesium oxide after heating & \SI{9.46}{g}\\
% Balance used & \#4\\
% Magnesium from sample bottle & \#1
% \end{tabular}

%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------

\section{The Security Principles of Saltzer and Schroeder}
We reached the following security principles: \\ 
\subsection{Principle of Economy of Mechanism}
We are simply limiting the total number of forked processes we can run
concurrently to prevent them from overloading our resources.
\subsection{Principle of Complete Mediation}
We are checking all existing processes for every cycle that our child has not
yet exited. While we cannot stop the process from forking, we can certainly
kill it to prevent the process from forking after that point in time.
\subsection{Principle of Least Privilege}
In addition to killing the processes when the hard limit has been reached, we
also lower the priority of the existing rogue processes to decrease the load on
the kernel. We also do not escalate privileges in our implementation - the 
shell is run with whatever permissions the user has.
\subsection{Principle of Psychological Acceptability}
As our implementation runs behind the scenes, there should be no discernable
difference for the end user. Unless they run a program that specifically 
requires a large number of forked processes, this will not inconvenience them 
in the slightest. \\ 

% \begin{tabular}{ll}
% Mass of magnesium metal & = \SI{8.59}{g} - \SI{7.28}{g}\\
% & = \SI{1.31}{g}\\
% Mass of magnesium oxide & = \SI{9.46}{g} - \SI{7.28}{g}\\
% & = \SI{2.18}{g}\\
% Mass of oxygen & = \SI{2.18}{g} - \SI{1.31}{}\\
% & = \SI{0.87}{g}
% \end{tabular}\\
% Because of this reaction, the required ratio is the atomic weight of magnesium: \SI{16.00}{g} of oxygen as experimental mass of Mg: experimental mass of oxygen or $\frac{x}{1.31}=\frac{16}{0.87}$ from which, $M_{\ce{Mg}} = 16.00 \times \frac{1.31}{0.87} = 24.1 = \SI{24}{g/mol}$ (to two significant figures).

%----------------------------------------------------------------------------------------
%	SECTION 4
%----------------------------------------------------------------------------------------

\section{Threat Model}
This is a classic example of a Denial of Service (DoS) attack. An attacker 
could exploit an unprepared program by feeding the shell a process that would
fork in an infinite loop. Our shell will do its best to allocate more and more
memory for every request each process makes. At best, this would cause his own 
session to reach its allocated limit and crash his session. At worst, if run 
with kernel permissions, it has the potential to use \textbf{all} available 
memory and resources in the system, causing a system wide failure and crashing 
all sessions on the machine. \\
It becomes imperative for a shell to recognize when an input is going bad and
stop it before it can cause too much damage. This means a designer must come up
with a metric to measure how malicious an input is - in our case, the more
processes a shell has forked, the higher the likelihood it is of being a
malicious input. \\

% The atomic weight of magnesium is concluded to be \SI{24}{g/mol}, as determined by the stoichiometry of its chemical combination with oxygen. This result is in agreement with the accepted value.

% \begin{figure}[h]
% \begin{center}
% \includegraphics[width=0.65\textwidth]{placeholder} % Include the image placeholder.png
% \caption{Figure caption.}
% \end{center}
% \end{figure}

%----------------------------------------------------------------------------------------
%	SECTION 5
%----------------------------------------------------------------------------------------

\section{Implementation}
In this section, we will discuss the details of our design implementation. We
have broken it down into the following modules:
\subsection{Polling the children}
To make our design work, we needed to change our current \verb+execute_command+
implementation. In our original implementation of lab 1b, we used 
\verb+waitpid+ to block our parent process, only returning once the child had
finished running. While perfectly adequate for the lab, we realized that in 
order for us to continuously update the number of newly spawned processes, we
would need to modify our design to poll the child process instead. So, instead 
of blocking in the parent process, waiting for the child to finish, we instead 
introduce a \verb+WNOHANG+ flag to \verb+waitpid+, which indicates that we 
will continue to poll the child periodically to check on its status instead of
``hanging'' the parent process until the child returns. \\

\subsection{Watchdog Function}
We created a watchdog function that would run in the parent process. Its duties
involved keeping track of the total number of processes and modifying the 
relative priority of these processes when certain soft limits were exceeded. 
This process was called in our \verb+execute-command+ function, and was
repeatedly run every time \verb+waitpid+ indicated that the child process had
not yet exited. \\
The following describe the different tasks that our watchdog accomplished:
\subsubsection{Counting processes}
In this first part of our approach, we want to monitor the total number of
processes on our shell. To accomplish this, we scanned the \verb+\proc+ folder
in the root directory of our Linux system. This folder houses information on
all running processes, organized by naming each directory after its PID. By 
using \verb+getpgrp()+ to identify the \textbf{process group ID} (PGID) of our 
shell, we then scanned through each of the process's \verb+\stat+ file, which 
housed a wealth of information. We compared each process's PGID and only 
proceeded if its PGID matched our shell's PGID, as this was where the initial
running processes were forked from. \\
From there, we would increment a counter every time we encountered a process 
with the same PGID as the shell. We would only update the final total if the
final PID encountered during that pass was greater than the final PID 
encountered during the last pass. This design choice was based on the simple
assumption that a forked process will have a higher PID than its parent -
therefore, if we do not encounter any processes with the same PGID but higher
PID, then we do not need to update the total number of processes, as there were
no new processes forked in between the two polling events.

\subsubsection{Playing nice}
As mentioned in the design overview, we also included soft limits in our design
to slow down legitimate processes that may simply require several forked 
processes. We ultimately decided to use three levels of soft limits, each 
divided into equal quarters of the hard limit. When the total number of forked
processes exceeded any of these limits, our watchdog program would adjust the 
nice levels accordingly, decreasing the priority of all forked processes until
the hard limit was reached. In addition, we would also print out a warning 
message every time this occurred, letting the user know that the priority of 
the shell processes was being lowered because they were utilizing too many
resources.

\subsubsection{Hitting the kill switch}
Once the hard limit was reached, we would print out a final message, letting 
the user know that he had reached the maxmium allowable number of processes.
We then ran a \verb+killpg+ command on all processes with the same process
group ID as the running process. This would also kill the shell, meaning no
further commands would be run from the script. \\

\subsection{Testing Environment}
Though at first, we ran our program on the UCLA CS Lion server, we realized
that it had the potential to affect other users who were running their own jobs
on the server. To that end, we changed out environment to the CS111 virtual 
machine distribution - if our shell or even our kernel crashed in the VM, it 
would be a trivial matter to reboot our system and try again. Modifying our 
test case such that it would not fork in an infinite loop was another viable
solution, to prevent our kernel from crashing in the first place. \\

%----------------------------------------------------------------------------------------
%	SECTION 6
%----------------------------------------------------------------------------------------

\section{Penetration Testing}

In this section, we will discuss the tests that we ran. This section will
include the instructions on how to run our demo against both good and 
malicious inputs.

\subsection{Running the demo}
To run our demo, we have included two extra files in our tarball. One is the
test script, \verb+testDesign.sh+, which consists of two commands. The first
command runs our malicious binary, and the second command is there just to
confirm that our shell has really killed itself and all of the other running
processes forked from the shell. That is to say, if we have really killed all
shell processes, then the second command should not run. \\
The second file is the source code of our malicious input, \verb+testFork.c+.
This file should be compiled using \verb+gcc testFork.c -o testFork+ to ensure
that the output binary file matches the binary file name in our test script. \\
To test our design against valid inputs, just run the timetrash function as you
would normally. Against a malicious input, there is no special flag to set - 
our watchdog function should detect improper behavior and shut it down before
it gets out of control. In this case, after compiling the testFork.c binary, 
you can test the design against a process overload attack by running
\verb+./timetrash testDesign.sh+. The code should then output the following:
\begin{lstlisting}
WARNING: Utilizing an unusually high number of resources
WARNING: Lowering priority of running processes
WARNING: Approaching upper limit on running processes
KILLING PROCESSES
Killed
\end{lstlisting}
One can then run \verb+pstree -g+ to verify that indeed, all of the rogue
\verb+timetrash+ processes have been killed.

\subsection{Designing the malicious input}
Our malicious input consists of the following:

\begin{lstlisting}
#include <getopt.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <sys/wait.h>
#include <stdio.h>
#include <stdlib.h>

int main() {
	// int i = 0;
	while(1) {
		fork();
		// i++;
	}
}
\end{lstlisting}
The sections that are commented out can be uncommented, along with modifying 
the while loop such that we fork a specified number of times, rather than
forking in an infinite loop. This became important later on, as we were testing
the robustness of our script to handle processes that forked a specified 
number of times. \\

The script that we run is very short, as mentioned earlier, and consists of 
only two lines:
\begin{lstlisting}
./testFork
pstree -g
\end{lstlisting}

\subsection{Time Testing}
As we were also modifying the priority of the extra forked processes, we used
the \verb+time+ command to check the run time of our code. To test this, we
would just prepend this command to all of the tests that we ran
(\verb+time ./timetrash testDesign.sh+), and it would output something in the 
format of the following at the end of every run:
\begin{lstlisting}
real	0m0.030s
user	0m0.003s
sys	0m0.020s
\end{lstlisting}
The idea is that without modifying the priority of the shell, we should see a
shorter runtime than in the case where we do modify the priority of the shell.
This would be due to our rogue processes yielding to higher priority processes,
increasing the run-time of the program on the whole.\\

% The accepted value (periodic table) is \SI{24.3}{g/mol} \cite{Smith:2012qr}. The percentage discrepancy between the accepted value and the result obtained here is 1.3\%. Because only a single measurement was made, it is not possible to calculate an estimated standard deviation. \\

% The most obvious source of experimental uncertainty is the limited precision of the balance. Other potential sources of experimental uncertainty are: the reaction might not be complete; if not enough time was allowed for total oxidation, less than complete oxidation of the magnesium might have, in part, reacted with nitrogen in the air (incorrect reaction); the magnesium oxide might have absorbed water from the air, and thus weigh ``too much." Because the result obtained is close to the accepted value it is possible that some of these experimental uncertainties have fortuitously cancelled one another.

%----------------------------------------------------------------------------------------
%	SECTION 7
%----------------------------------------------------------------------------------------

\section{Robustness Analysis}

In this section, we will analyze how effective our implementation was at
detecting and killing process overload attacks, while still allowing other 
processes to go about their merry way. We will also discuss the tradeoffs of
going from a blocking method to polling the children in our implementation. \\

To begin, we were successful in achieving our primary goal of killing the rogue
processes before they overloaded the kernel. The watchdog function was 
successful in detecting the increased number of new processes, and was also 
successful in identifying which of these new processes were forked from the
shell. When it came time to kill all of these rogue processes, our watchdog had
no trouble determining which group of processes to send the kill signal to,
which it did quickly and efficiently. There was no ambiguity about which 
processes needed to be terminated, meaning no bystander processes were 
accidentally killed. \\
As for our secondary goal, we did include a method that updated the priority
level of our group of processes. However, as we went to benchmark our update
with the \verb+time+ command, we noticed no discernable difference between the
times we were achieving when we were decreasing the priority and the times we
were achieving when we were not. This may have been caused by the fact that we 
were not running a lot of other, higher priority processes at the same time of
our tests. In this case, modifying the relative priority of our rogue processes
will have no effect simply because there are no other processes for our newly 
made nice processes to yield to. \\

Changing our implementation from blocking to polling had no noticeable effect
on our runtime. However, if we had a long running child (such as a process that
hits an infinite loop), it is possible that this could affect our run-time 
performance. Namely, when a process is \textbf{blocked}, it indicates to the 
kernel that it is entering a blocked state, and asks only to be awoken when
the process that it is blocking on (ie. its child) has finished running. This
improves the throughput of our system on the whole, as the kernel knows that it
does not have to waste time swapping in the blocked process before its wake
condition has been met.\\
However, when \textbf{polling}, we let the kernel know that we are actually 
still in a running state. Our code is constantly asking the child process 
whether it has finished or not, costing the system in time and decreasing the 
throughput of our system on the whole. Yet this change was a necessity for our 
watchdog function to perform reliably - after all, if we ran the watchdog once 
in our parent process, then blocked on our child, and only ran our watchdog 
again after the child had completed, then our watchdog would have been fast 
asleep while a potentially malicious child can run amok and fork all it wants. 
Therefore, we made the tradeoff of decreasing the overall throughput of our
system in order to better monitor the behavior of every command that we run
through our shell. \\


% \begin{enumerate}
% \begin{item}
% The \emph{atomic weight of an element} is the relative weight of one of its atoms compared to C-12 with a weight of 12.0000000$\ldots$, hydrogen with a weight of 1.008, to oxygen with a weight of 16.00. Atomic weight is also the average weight of all the atoms of that element as they occur in nature.
% \end{item}
% \begin{item}
% The \emph{units of atomic weight} are two-fold, with an identical numerical value. They are g/mole of atoms (or just g/mol) or amu/atom.
% \end{item}
% \begin{item}
% \emph{Percentage discrepancy} between an accepted (literature) value and an experimental value is $\frac{|\mathrm{experimental result} - \mathrm{accepted result}|}{\mathrm{accepted result}}$.
% \end{item}
% \end{enumerate}

%----------------------------------------------------------------------------------------
%	SECTION 8
%----------------------------------------------------------------------------------------


\section{Results}

In this section, we will discuss our results, document the known bugs in our 
code, and close with the challenges that we encountered along the way. \\ 

\subsection{Summary}
We reached our primary objective, and believe we have also reached our 
secondary objective, though we were unable to come up with a way to test 
whether we had reached the secondary objective. Still, by successfully 
defending against a process overload attack, we made our shell that much more
secure against malicious users.

\subsubsection{Division of Work}
Spencer implemented the process counting and killing, while Li implemented the
process priority setting. \\

\subsection{Known Bugs}
When we run our infinite loop fork test, our shell very quickly detects and
shuts down our shell. However, if we were to manually set the number of forked 
processes per process, our shell begins to exhibit undefined behavior between 
$i = 5$ and $i = 15$ forks per process. Anything less than 5 will complete
before our watchdog detects it, and anything more than 15 will be detected by
our watchdog and dealt with accordingly. But when we fork $5 - 15$ times per
process, the shell begins to complain that it is unable to open the file, and
seems to crash on its own volition. Other times, it would crash the first 
command, yet still run the rest of the commands in our shell script. We were 
unable to determine the cause of this bug.\\
In addition, possibly owing to the fact that our hard limit is set to only
$100$ processes, there is no significant deviation from a runtime of about
$20ms$, regardless of how many forked processes we introduce. As mentioned 
before, we are uncertain as to whether this constitutes a bug, or if we needed
to introduce other, higher priority processes to run concurrently. \\

\subsection{Challenges}
We encountered a number of challenges along the way. Outside of the usual 
debugging process, here were the main challenges that beset our progress:
\subsubsection{Method to count the processes}
Although running \verb+pstree+ could quickly show which processes were forked
from where, it did not seem to work quite as nicely as one would have hoped for
when there were an overwhelming number of processes being forked at once. 
Namely, the forked processes did not all stem from a single parent. Therefore, 
we needed another way to find out how all of the processes were related to each
other. \\
After a bit of research, we determined that all of the forked processes shared 
a process group ID. This could be verified by running \verb+pstree -g+.
Furthermore, commands like \verb+pstree+ or \verb+ps+ would refer to the
directory \verb+\proc+ to get the information they needed. It was a simple 
matter of researching how to access a directory in C and all of its contents, 
then iterating through all of the process folders to see which processes 
belonged to the same group and which did not. Though we did hit a snag when we
conflated a process's \textbf{thread group ID} and its \textbf{process group 
ID}, we quickly rectified our mistake after a few tests and began to properly
account for all of the running processes forked from the shell.
\subsubsection{Polling the child's forked processes}
In our original implementation of lab 1b, we would used \verb+waitpid+ to block
the parent process, and only return when after the child had completed. As
mentioned in the Implementation section, this blocking method needed to be 
changed in order for us to effectively monitor all of the newly forked child 
processes in a malicious input. Unfortunately, the blocking method of using
\verb+waitpid+ was all that we knew how to do. Fortunately, after a quick read
of the \verb+waitpid+ man pages, it seemed like the function \verb+waitpid+ 
had a fair amount of flexibility to it, and allowed us to pass the
\verb+WNOHANG+ flag to switch from a blocking method of waiting on its 
children, to a polling method.
\subsubsection{Updating the nice level for all forked processes}
As mentioned in previous sections of this design report, we wished to update
the nice level of these forked processes after the malicious process has been
executed by our script. We realized that after our shell had executed the 
command, the new process was outside of our direct control - it was in its own
space now, running in a completely different memory location set aside for its
own process. \\
However, we determined that all of these forked processes did have one thing in
common, and that was that they all had the same process group ID. After reading
into the \verb+nice+ command and finding its cousin, \verb+setpriority+, it was
a trivial matter to update the nice levels of all of the processes that shared
the same process group ID.

\end{document}